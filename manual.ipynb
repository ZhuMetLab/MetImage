{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Manual of MetImage (0.3.0)\n",
    "\n",
    "## Content for manual\n",
    "1. Introduction\n",
    "2. Dataset parparation\n",
    "3. Image conversion\n",
    "4. Split datasets\n",
    "5. Tile split and tile selection\n",
    "6. Model building\n",
    "7. Model training\n",
    "8. To do list\n",
    "\n",
    "## 1. Introduction\n",
    "MetImage is a python based approach to convert LC–MS-based untargeted metabolomics data into digital images. MetImage encoded the raw LC–MS data into multi-channel images, and each image retained the characteristics of mass spectra from the raw LC–MS data. MetImage can build diagnose model by multi-channel images with deep learning model."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2: Dataset parparation\n",
    "### 1. Raw LC-MS data\n",
    "MS1 data conversion: Convert raw MS data files (e.g., Agilent .d files, Sciex .wiff files and Thermofisher .raw files) to mzXML format using ProteoWizard (version 3.0.6150). Only MS1 peak picking for following conversion.\n",
    "\n",
    "### 2. Create dataset\n",
    "Copy datasets into an independent dir named such as \"Rawdata\".\n",
    "    .\\Rawdata\n",
    "        ├─File1.mzxml\n",
    "        └ File2.mzxml\n",
    "\n",
    "If you want to construct diagnosis model, please creat subfolders with name of groups, and then copy .mzxml files in corresponding subfolders.\n",
    "    .\\Rawdata\n",
    "        ├─Group1\n",
    "            ├─File1.mzxml\n",
    "            └ File2.mzxml\n",
    "        └ Group2\n",
    "            ├─File1.mzxml\n",
    "            └ File2.mzxml"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 3: Image conversion\n",
    "    DataConverter can convert raw LC-MS data (.mzXML) into digital image matrix. To use DataConverter, the dataset is processed using the code shown below:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import metimage\n",
    "from metimage.datas.DataConverter import ConvertDataset\n",
    "rawdata_dir = metimage.__path__ [0]+\"/demo/Rawdata\"\n",
    "save_path = metimage.__path__ [0]+\"/demo/Convert\"\n",
    "ConvertDataset(rawdata_dir,pattern=\"mzXML\",mzmin=60, mzmax=1200, binSize=0.01, Threads=6, save_path=save_path)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Parameters:\n",
    "(1) rawdata_dir: the dir of dataset, containing .mzXML files.\n",
    "(2) pattern: MS data format. (default mzXML)\n",
    "(3) mzmin: the minimum value of m/z bin\n",
    "(4) mzmax: the maximum value of m/z bin\n",
    "(5) binSize: the Da of every bin in m/z binning\n",
    "(6) Threads: number of thread used for multiprocessing\n",
    "(7) save_path: the dir of outputs (whole image, .npz)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 4: Split datasets (optional)\n",
    "\n",
    "__Note: If you want to predict unlabelled sample with trained model, please skip chapter 4, chapter 5 and chapter 7.__\n",
    "\n",
    "In common, a training set, a validation set and a testing set are necessary for model training and testing. At least training set and validation set are necessary for training. Given that the user may split their dataset in different methods, MetImage doesn't provide automated dataset split fuctions. Instead, a stratified sampling method is provided to split training set and validation set. Please refer to following code to split your datasets."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import metimage\n",
    "from metimage.utils.SplitDataset import SplitDataset\n",
    "dataset_wd = metimage.__path__ [0]+\"/demo/Convert\"\n",
    "SplitDataset(dataset_wd, test_split=0.3, seed=42)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Parameters:\n",
    "(1) dataset_wd: the dir of __converted__ dataset, containing .npz files.\n",
    "(2) test_split: the ratio of validation dataset. test_split = 0.3 means 30% samples of dataset split as testing set.\n",
    "(3) seed: seed used for sampling. (Use consistent seed number to keep reproducibility.)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 5: Tile split and tile selection (optional)\n",
    "\n",
    "__Note: If you want to use all tiles to construct a deep learning model, please skip this chapter.__\n",
    "\n",
    "MetImage provides two indictors to select information rich tiles, 1D image entropy and pooled intensity of tiles. We recommand __only__ us training set to select tiles. Please create selected tiles list with following codes:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import metimage\n",
    "from metimage.datas.TileSelection import GenerateIndex, SelectTiles\n",
    "dataset_wd = metimage.__path__ [0]+\"/demo/Convert/train\"\n",
    "save_path = metimage.__path__ [0]+\"/demo/Convert\"\n",
    "GenerateIndex(dataset_wd,cal_mean=True,cal_entropy = True,pixelx=224, pixely=224, overlap_col=0, overlap_row=0,save_path=save_path)\n",
    "Sampling_list = SelectTiles(dir_mean=save_path+\"/mean\", dir_entropy=save_path+\"/1DEntropy\", TopMean=1000, TopEntropy=1000,save_path=save_path)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Parameters:\n",
    "(1) dataset_wd: the dir of __converted__ dataset, containing .npz files.\n",
    "(2) cal_mean, cal_entropy: calculate pooled intensity or 1D image entropy.\n",
    "(3) pixelx,pixely: the width (x) and length (y) of every tile in pixel.\n",
    "(4) overlap_col,overlap_row: the overlap width (col) and length (row) value of tiles split in pixel.\n",
    "(5) save_path: the dir of outputs\n",
    "(6) dir_mean: pathway of calculated pooled intensity. (.etp)\n",
    "(7) dir_entropy: pathway of calculated 1D image entropy. (.etp)\n",
    "(8) TopMean: Top N pooled intensity selected.\n",
    "(9) TopEntropy: Top N entropy selected.\n",
    "\n",
    "Note: If only pooled intensity or 1D image entropy is used for tile selection, please set another varible as __None__ (eg. TopMean=None)\n",
    "\n",
    "__After the tile selection, a Samplinglist.lst file will be generated. This file contained indexes of selected tiles. Please copy the generated Samplinglist.lst file for training or prediction.__"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 6: Model building\n",
    "### 6.1 load selected tiles index\n",
    "Please load list of selected tiles index before model construction."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import metimage\n",
    "from metimage.models.train import ParseIndex\n",
    "Sampling_list = ParseIndex(lst_dir=metimage.__path__ [0]+\"/demo/Convert/Samplinglist.lst\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Parameters:\n",
    "(1) lst_dir: the dir of Samplinglist.lst files."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 6.2 Construct deep learning model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 6.2.1 use bulit-in ResNet model\n",
    "MetImage provide a ResNet (Residual neural network) model as an example to build deep learning model.\n",
    "To know about ResNet, please refer to [Link](https://doi.org/10.48550/arXiv.1512.03385)\n",
    "To call this model, please use following methods:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from metimage.models.train import MakeModel\n",
    "model = MakeModel(Tiles_no=len(Sampling_list))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 6.2.2 use customized deep learning model\n",
    "To use other customized deep learning model (eg. VGG-19), please modified the source code.\n",
    "(1) Copy the model in MetImage/models\n",
    "(2) Replace the ResNet_v2 in function MakeModel and LoadModel into customized deep learning model."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 7: Model training\n",
    "### 7.1 Train deep learning model\n",
    "Before the model training, please check the following list and ensure all object prepared before.\n",
    "- training set\n",
    "- validation set\n",
    "- multi-channel model (constructed in chapter 6)\n",
    "- Sampling_list (selected tiles index, loaded in chapter 6)\n",
    "\n",
    "Then training the model by following codes:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import metimage\n",
    "from metimage.models.train import train\n",
    "train_dir = metimage.__path__ [0]+\"/demo/Convert/train\"\n",
    "test_dir = metimage.__path__ [0]+\"/demo/Convert/validation\"\n",
    "save_path = metimage.__path__ [0]+\"/demo/Convert\"\n",
    "trained_model = train(train_dir= train_dir, test_dir= test_dir, batch_size = 4, model=model, Sampling_list=Sampling_list, seed=42, save_dir=save_path, epochs=10, workers=6, Augmentation=False, save_during_training=False, earlystopping=False, save_best_model=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Parameters:\n",
    "(1) train_dir: the dir of training set.\n",
    "(2) test_dir: the dir of validation set.\n",
    "(3) batch_szie: batch size for model training.\n",
    "(4) model: deep learning model.\n",
    "(5) Sampling_list: selected tiles index (list)\n",
    "(6) seed: seed used for model training.\n",
    "(7) save_dir: the dir of outputs (information of model training, model weight)\n",
    "(8) epoch: maxinum training epoch for model training. Training will be stopped when achieves the epoch.\n",
    "(9) workers: worker used for model training.\n",
    "(10) Augmentation: use data augmentation (bool, refer to 7.3)\n",
    "(11) save_during_training: save model weights during model training. (bool, refer to 7.4)\n",
    "(12) earlystopping: apply earlystop or not. (bool, refer to 7.5)\n",
    "(13) save_best_model: save model weights of best model. (bool)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 7.2 Monitor model training\n",
    "In default, log of training will output in save_path/log. The training process can be visualized in tensorbroad by following code. (Use Linux or terminal)\n",
    "    tensorboard --logdir='save_path/log'"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 7.3 Data augmentation\n",
    "MetImage can simulate the shift of retention time, m/z and intensity by applying random disturbance in the range set by user. To apply augmentation, the following parameters need to be added in function train.\n",
    "(1) RT_shift: maxinum pixels of RT shift for tiles. (Default: 20)\n",
    "(2) MZ_shift: maxinum pixels of RT shift for tiles. (Default: 10)\n",
    "(3) Int_shift: a list of fold for intensity shift range. Int_shift = [0.1,10] reperesents intensity changed between 0.1 times and 10 times. (Default: [0.1,10])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 7.4 Checkpoints\n",
    "MetImage can save model weights during training with a certain interval. For example, if you want to record model weights every 10 epochs, please add following parameters in function train.\n",
    "save_during_training=True, save_epoch=10\n",
    "parameters:\n",
    "(1) save_epoch: the interval of saving model weights. (Default: 10)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 7.5 Earlystopping\n",
    "To determine best model and avoid overfitting, earlystopping is provided. Please add following parameters in function train to apply earlystopping.\n",
    "(1) min_delta: Minimum change in loss of validation set to qualify as an improvement. (Default: 0)\n",
    "(2) patience: Number of epochs with no improvement after which training will be stopped.\n",
    "To understand earlystopping, refer to *tf.keras.callbacks.EarlyStopping*"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 7: Model evaluation\n",
    "### 7.1 Load trained model\n",
    "Before evaluate a trained model, please check the following list and ensure all object prepared before.\n",
    "- testing set or unlabelled sample.\n",
    "- multi-channel model (constructed in chapter 6)\n",
    "- Sampling_list (selected tiles index, loaded in chapter 6)\n",
    "- weight of model (trained in chapter 7)\n",
    "\n",
    "Use following codes to load a trained model:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import metimage\n",
    "from metimage.models.train import LoadModel, ParseIndex\n",
    "Sampling_list = ParseIndex(lst_dir=metimage.__path__ [0]+\"/checkpoints/Samplinglist.lst\")\n",
    "model = LoadModel(Tiles_no=len(Sampling_list), weight_dir=metimage.__path__ [0]+\"/checkpoints/best_weights.hdf5\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "parameters:\n",
    "(1) weight_dir: pathway of model weight (.cpkt, .h5 or .hdf5)\n",
    "\n",
    "To evaluate a testing set, refer to 7.2.\n",
    "To predict unlabelled samples, refer to 7.3."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 7.2 Evaluate model performance\n",
    "Please use following code to evaluate model performance:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import metimage\n",
    "from metimage.models.train import Model_evaluation\n",
    "Model_evaluation(test_dir = metimage.__path__ [0]+\"/demo/Convert/test\", model=model, Sampling_list=Sampling_list, workers=12)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "parameters:\n",
    "(1) test_dir: dir of testing set.\n",
    "(2) model: deep learning model.\n",
    "(3) Sampling_list: selected tiles index (list)\n",
    "(4) workers: worker used for model training."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 7.3 Predict unlabelled sample\n",
    "Please use following code to predict unlabelled samples:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import metimage\n",
    "from metimage.models.train import Model_prediction\n",
    "Model_prediction(pred_dir=metimage.__path__ [0]+\"/demo/Convert/test\", model=model, Sampling_list=Sampling_list, print=True,save_dir=metimage.__path__ [0]+\"/demo/Convert\",workers=12)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "parameters:\n",
    "(1) pred_dir: dir of unlabelled sample(s).\n",
    "(2) model: deep learning model.\n",
    "(3) Sampling_list: selected tiles index (list)\n",
    "(4) print: write the prediction probability value or not. (bool)\n",
    "(5) save_dir: output dir for prediction results.\n",
    "(6) workers: worker used for model training.\n",
    "\n",
    "If set print is true, the prediction results will be output in savedir/prediction.csv"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 8: To do list\n",
    "- Visualization module\n",
    "- Automated biological interperation\n",
    "- Information enrichment mode (without tile selection)\n",
    "- Inference mode (reduce size of model)"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
